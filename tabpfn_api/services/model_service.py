import logging
from typing import List, Dict, Any
import uuid
from fastapi import HTTPException, status

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from tabpfn_api.models.user import User
from tabpfn_api.models.model import ModelMetadata
from tabpfn_api.tabpfn_interface.client import fit_model, TabPFNInterfaceError, predict_model
from tabpfn_api.core.security import decrypt_token, InvalidToken

log = logging.getLogger(__name__)


class ModelServiceError(Exception):
    """Custom exception for model service layer errors."""
    pass


async def train_new_model(
    db: AsyncSession,
    current_user: User,
    features: List[List[Any]],
    target: List[Any],
    feature_names: List[str] | None = None,
    config: Dict[str, Any] | None = None
) -> str:
    """Trains a new TabPFN model, stores metadata, and returns the internal model ID.

    Args:
        db: The async database session.
        current_user: The authenticated User object (contains user_id and encrypted token).
        features: List of lists representing feature data.
        target: List representing target data.
        feature_names: Optional list of feature names.
        config: Optional dictionary of configuration for TabPFN's fit method.

    Returns:
        The internally generated UUID (as string) for the trained model.

    Raises:
        ModelServiceError: If decryption fails, TabPFN fitting fails, or DB operations fail.
    """
    config = config or {} # Ensure config is a dict
    log.info(f"User ID {current_user.id} initiating model training.")

    # 1. Decrypt the user's TabPFN token
    try:
        decrypted_tabpfn_token = decrypt_token(current_user.encrypted_tabpfn_token)
        log.debug(f"Successfully decrypted TabPFN token for user ID {current_user.id}.")
    except InvalidToken:
        log.error(f"Failed to decrypt TabPFN token for user ID {current_user.id}. Possible key mismatch or data corruption.")
        # This indicates a server configuration issue or data integrity problem.
        raise ModelServiceError("Internal error: Could not decrypt stored credentials.")
    except Exception as e:
        log.exception(f"Unexpected error decrypting token for user {current_user.id}")
        raise ModelServiceError(f"Internal error during credential decryption: {e}")

    # 2. Call the TabPFN interface to fit the model
    try:
        tabpfn_train_set_uid = fit_model(
            tabpfn_token=decrypted_tabpfn_token,
            features=features,
            target=target,
            config=config
        )
        log.info(f"TabPFN fitting complete for user ID {current_user.id}. train_set_uid: {tabpfn_train_set_uid}")
    except TabPFNInterfaceError as e:
        log.warning(f"TabPFN interface error during fitting for user ID {current_user.id}: {e}")
        # Pass the interface error message upwards, potentially map to HTTP errors later
        raise ModelServiceError(f"Failed to train model: {e}") from e
    except Exception as e:
        log.exception(f"Unexpected error during model fitting process for user {current_user.id}")
        raise ModelServiceError(f"An unexpected internal error occurred during model training: {e}") from e

    # 3. Prepare and save metadata to the database
    try:
        # Calculate basic metadata
        sample_count = len(features)
        feature_count = len(features[0]) if sample_count > 0 else 0

        # Create the ModelMetadata object (internal_model_id is generated by default)
        db_model_metadata = ModelMetadata(
            tabpfn_train_set_uid=tabpfn_train_set_uid,
            user_id=current_user.id,
            feature_count=feature_count,
            sample_count=sample_count,
            feature_names=feature_names, # Store provided feature names
            tabpfn_config=config # Store the config used
        )

        db.add(db_model_metadata)
        await db.commit()
        await db.refresh(db_model_metadata)

        internal_model_id = str(db_model_metadata.internal_model_id) # Convert UUID to string for return
        log.info(f"Successfully saved ModelMetadata for user ID {current_user.id}. Internal model ID: {internal_model_id}")

        return internal_model_id

    except Exception as e:
        log.exception(f"Failed to save ModelMetadata to database for user ID {current_user.id} after successful TabPFN fit (train_set_uid: {tabpfn_train_set_uid}). Rolling back.")
        await db.rollback()
        # This is problematic: the model was trained in TabPFN, but we couldn't record it.
        # Consider adding cleanup logic or marking it as orphaned if possible.
        raise ModelServiceError("Failed to save model metadata after training.") from e 

async def get_predictions(
    db: AsyncSession,
    current_user: User,
    internal_model_id: str,
    features: List[List[Any]],
    task: str,
    output_type: str = "mean",
    config: Dict[str, Any] | None = None
) -> List[Any]:
    """Get predictions using a previously trained model.

    Args:
        db: The async database session.
        current_user: The authenticated User object.
        internal_model_id: The internal UUID of the trained model.
        features: List of lists representing feature data to predict on.
        task: The type of task ("classification" or "regression").
        output_type: The type of prediction output (e.g., "mean", "median", "mode" for regression).
        config: Optional dictionary of configuration options.

    Returns:
        The predictions as a list or dictionary (depending on output_type).

    Raises:
        ModelServiceError: If model not found, user doesn't own model, or prediction fails.
    """
    log.info(f"User ID {current_user.id} requesting predictions for model {internal_model_id}")

    # 1. Look up the model metadata
    model_metadata = None # Initialize
    try:
        # Convert the input string ID to a UUID object
        try:
            model_uuid = uuid.UUID(internal_model_id)
        except ValueError:
            log.warning(f"Invalid UUID format provided for model ID: {internal_model_id}")
            # Treat invalid UUID format as model not found
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Model not found")

        # Query the database
        stmt = select(ModelMetadata).where(ModelMetadata.internal_model_id == model_uuid)
        result = await db.execute(stmt)
        model_metadata = result.scalar_one_or_none()

    except Exception as e:
        # Catch unexpected database errors during the query execution
        log.exception(f"Unexpected database error while looking up model {internal_model_id}")
        # Raise a generic service error for unexpected DB issues
        raise ModelServiceError("Database error while retrieving model details") from e

    # Handle Model Not Found case *after* the DB query attempt
    if not model_metadata:
        log.warning(f"Model with UUID {model_uuid} not found in database")
        # Raise the specific error that the API layer expects for a 404
        raise ModelServiceError("Model not found")

    # Verify ownership (only if model was found)
    if model_metadata.user_id != current_user.id:
        log.warning(f"User {current_user.id} attempted to access model {internal_model_id} owned by user {model_metadata.user_id}")
        raise ModelServiceError("Access denied: You do not own this model")

    log.debug(f"Found model metadata for {internal_model_id}. train_set_uid: {model_metadata.tabpfn_train_set_uid}")

    # 2. Decrypt the user's TabPFN token
    try:
        decrypted_tabpfn_token = decrypt_token(current_user.encrypted_tabpfn_token)
        log.debug(f"Successfully decrypted TabPFN token for user ID {current_user.id}")
    except InvalidToken:
        log.error(f"Failed to decrypt TabPFN token for user ID {current_user.id}")
        raise ModelServiceError("Internal error: Could not decrypt stored credentials")
    except Exception as e:
        log.exception(f"Unexpected error decrypting token for user {current_user.id}")
        raise ModelServiceError(f"Internal error during credential decryption: {e}")

    # 3. Call the TabPFN interface to get predictions
    try:
        predictions = predict_model(
            tabpfn_token=decrypted_tabpfn_token,
            train_set_uid=model_metadata.tabpfn_train_set_uid,
            features=features,
            task=task,
            output_type=output_type,
            config=config
        )
        log.info(f"Successfully got predictions for model {internal_model_id}")
        return predictions

    except TabPFNInterfaceError as e:
        log.warning(f"TabPFN interface error during prediction for model {internal_model_id}: {e}")
        raise ModelServiceError(f"Failed to get predictions: {e}") from e
    except Exception as e:
        log.exception(f"Unexpected error during prediction process for model {internal_model_id}")
        raise ModelServiceError(f"An unexpected internal error occurred during prediction: {e}") from e 